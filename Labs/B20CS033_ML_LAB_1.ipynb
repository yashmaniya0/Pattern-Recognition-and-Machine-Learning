{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B20CS033_ML_LAB_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 1 (Basic of Python):**\n",
        "Perform the following operations in python. (10 Marks)\\\n",
        "\\\n",
        "a. Convert file data to list (1 Marks)"
      ],
      "metadata": {
        "id": "Pz9fNJ1GCnUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "l=[]\n",
        "raw_data=''\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Lab 1/q1.csv','r') as f:\n",
        "    raw_data=f.read()\n",
        "\n",
        "ll=raw_data[:-2].split('\\n')\n",
        "for i in ll:\n",
        "    row=i.split(',')\n",
        "    if len(row)==0:\n",
        "        continue\n",
        "    row = [float(x) if len(x) else 0 for x in row]\n",
        "    l.append(row)\n",
        "    \n",
        "print(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqDrKsnkDFny",
        "outputId": "c077173d-97df-49f4-81c6-d5146957e94c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.364, 1.263, 0.0, 0.0], [1.263, 2.901, 0.0, 1.0], [2.901, 4.523, 0.0, 1.0], [4.523, 6.229, 0.0, 1.0], [6.229, 7.901, 0.0, 1.0], [7.901, 9.507, 0.0, 1.0], [9.507, 11.162, 0.0, 1.0], [11.162, 12.918, 0.0, 1.0], [12.918, 14.64, 0.0, 1.0], [14.64, 16.447, 0.0, 1.0], [16.447, 18.119, 0.0, 1.0], [18.119, 19.908, 0.0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Convert User Input to a Number (1 Marks)"
      ],
      "metadata": {
        "id": "401SySwWDLHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(input('input : '))\n",
        "print(n,type(n))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIAADu7TDQGi",
        "outputId": "8465b476-6cb7-4049-c2b2-21b824bec933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input : 165448\n",
            "165448 <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Convert String to Datetime in Python (1 Marks)"
      ],
      "metadata": {
        "id": "hAzwx7XNDq5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "date_string = \"18 January 2022  01:15:40\"\n",
        "date_object = datetime.strptime(date_string, \"%d %B %Y  %H:%M:%S\")\n",
        "\n",
        "print(date_object)\n",
        "print(type(date_object))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9lVHlGWDvw8",
        "outputId": "6fddfb24-3fee-4f5b-e395-953c24e16130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-18 01:15:40\n",
            "<class 'datetime.datetime'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. How to call external commands in Python? (1 Marks)"
      ],
      "metadata": {
        "id": "3owILoaMGZ8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "msg = \"echo example of an External Command\"\n",
        "print(os.popen(msg).read())"
      ],
      "metadata": {
        "id": "Wb4TdeHgGeNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed22ab9-9854-4852-cf72-8a64fa1b8cd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example of an External Command\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e. How to count the occurrences of a list item? (1 Marks)"
      ],
      "metadata": {
        "id": "5Pwzep27GfmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = [1,2,2,2,3,4,5,6,2,3,2]\n",
        "\n",
        "# counting the number of occurances of 2 in l\n",
        "\n",
        "ans = 0\n",
        "\n",
        "for i in l:               # however we can directly use : ans=l.count(2) \n",
        "  if i==2:\n",
        "    ans+=1\n",
        "\n",
        "print('number of occurances of 2 in l =',ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4V0QOjKGiNN",
        "outputId": "37d4f90e-4ddc-40aa-e9ac-4742aad34163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of occurances of 2 in l = 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f. How to flatten lists in Python? (1 Marks)"
      ],
      "metadata": {
        "id": "BT-qRHNRHcej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(l : list):\n",
        "    ans=[]\n",
        "    for i in l:\n",
        "        if isinstance(i,list):\n",
        "            ans+=flatten(i)\n",
        "        else:\n",
        "            ans.append(i)\n",
        "    return ans\n",
        "\n",
        "l=[1,2,[3,[4,5]],[6,7,8],9,10]\n",
        "\n",
        "print(flatten(l))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrYvKuChHgFl",
        "outputId": "a36704f4-77a9-4b72-e525-82b52fff35ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "g. How to merge dictionaries in Python? (1 Marks)"
      ],
      "metadata": {
        "id": "i2tC9QvVJKio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
        "d2 = {'e': 5, 'f': 6, 'g': 7, 'h': 8}\n",
        "\n",
        "D = d1.copy()\n",
        "D.update(d2)\n",
        "\n",
        "print(D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyMuRg-zJNYA",
        "outputId": "88480a2f-18f8-42d9-a1c7-9f6d08879a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "h. Remove duplicate items from a list in Python? (1 Marks)"
      ],
      "metadata": {
        "id": "zYHz3eMtJzuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = [1,2,2,2,3,4,5,6,2,3,2]\n",
        "ans = list(set(l))\n",
        "\n",
        "print(ans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F11YzCwQJ0UU",
        "outputId": "446dfc0e-ede7-4153-8788-640a5a7abb85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i. Write a Python script to check whether a given key already exists in a dictionary. (2 Marks)"
      ],
      "metadata": {
        "id": "6Txzy8UVKHrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_in(k,d):\n",
        "    if k in d.keys():\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "d = {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8}\n",
        "\n",
        "k1 = 'd'\n",
        "k2 = 'x'\n",
        "\n",
        "print(f'Check if \\'{k1}\\' is in dictionary : {is_in(k1,d)}')\n",
        "print(f'Check if \\'{k2}\\' is in dictionary : {is_in(k2,d)}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGjtbV_WKIUu",
        "outputId": "31e2f7f3-fac1-44c3-cb35-0380e51281ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check if 'd' is in dictionary : True\n",
            "Check if 'x' is in dictionary : False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\\\n",
        "# **Problem 2 (Numpy) :** \n",
        "Using numpy create two matrices of same size of your choice, fill the non-zero values into these two matrices. Now perform following: (10 Marks)\\\n",
        "\\\n",
        "(a) Display first row of first matrix"
      ],
      "metadata": {
        "id": "dHvUugTeLQ7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "b = [[10, 11, 12], [13, 14, 15], [16, 17, 18]]\n",
        "\n",
        "m1 = np.array(a)\n",
        "m2 = np.array(b)\n",
        "\n",
        "print(f'Matrix 1 : \\n{m1}\\n')\n",
        "print(f'Matrix 2 : \\n{m2}\\n')\n",
        "\n",
        "print('First row of first matrix : ',m1[0, :],'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHMdSBsKLffw",
        "outputId": "cfbf5674-1b71-4f1c-bde9-7f5728e22170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix 1 : \n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            "Matrix 2 : \n",
            "[[10 11 12]\n",
            " [13 14 15]\n",
            " [16 17 18]]\n",
            "\n",
            "First row of first matrix :  [1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Display second column of second matrix"
      ],
      "metadata": {
        "id": "QYWpyctCNe9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Second column of second matrix :  {m2[:,1]}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_mGv1LUNiGZ",
        "outputId": "47737792-6cd3-408e-e17e-5b9c229bfcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second column of second matrix :  [11 14 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Perform matrix multiplication"
      ],
      "metadata": {
        "id": "XNNyKKplN3Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Matrix Multiplication ( m1 * m2 ) :\\n{np.matmul(m1,m2)}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Jb7aH8N9Aj",
        "outputId": "5b20ad72-2581-4660-db8b-d540d896d0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication ( m1 * m2 ) :\n",
            "[[ 84  90  96]\n",
            " [201 216 231]\n",
            " [318 342 366]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(d) Perform element-wise multiplication"
      ],
      "metadata": {
        "id": "fGs_GCYJOXVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Element wise multiplication ( m1 * m2 ):\\n{m1*m2}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUH7ZPnsOap6",
        "outputId": "d76017ad-af86-4e1d-b3bb-dab473dc7790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element wise multiplication ( m1 * m2 ):\n",
            "[[ 10  22  36]\n",
            " [ 52  70  90]\n",
            " [112 136 162]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(e) Perform dot product between each column of first matrix and each column of second matrix"
      ],
      "metadata": {
        "id": "RaBK2vPTOs68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r = np.shape(m1)[0]\n",
        "c = np.shape(m1)[1]\n",
        "\n",
        "M = np.ndarray((r, c), dtype=int)\n",
        "\n",
        "for i in range(c):\n",
        "    x = 0\n",
        "    for j in range(r):\n",
        "        x += m1[j][i]*m2[j][i]\n",
        "    for ix in range(r):\n",
        "        M[ix][i] = x\n",
        "\n",
        "print(f'Dot product between columns of m1 and m2 : \\n{M}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jG2lWghOzlZ",
        "outputId": "b4665def-8a7e-44ec-e428-9b3d240051d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot product between columns of m1 and m2 : \n",
            "[[174 228 288]\n",
            " [174 228 288]\n",
            " [174 228 288]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\\\n",
        "# **Problem 3 (Pandas) :**\n",
        "A csv file has been provided to you at this link. The given dataset is related\n",
        "to cars and contains 26 columns.In the given dataset, “Price” is the target variable. (15 Marks)\\\n",
        "\\\n",
        "i) Assign a type to each of the following features (a) Model, (b)Type, (c) Max. Price and (d)Airbags from the following: ordinal/nominal/ratio/interval scale. (1 Marks)"
      ],
      "metadata": {
        "id": "VK8GZNEGSYTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model     -> Nominal\n",
        "# Type      -> Ordinal\n",
        "# Max.Price -> Ratio\n",
        "# Airbags   -> Nominal"
      ],
      "metadata": {
        "id": "pgC5hj-bS36r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii) Write a function to handle the missing values in the dataset (e.g., any NA, NaN values). (2\n",
        "Marks)"
      ],
      "metadata": {
        "id": "ESwBmwdYS-vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "\n",
        "def clean_data(df:pandas.DataFrame):\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "df = pandas.read_csv('/content/drive/MyDrive/Colab Notebooks/Lab 1/Cars93.csv')\n",
        "print(df.head())\n",
        "print(\"No. of missing values before cleaning data : \",df.isnull().sum().sum())\n",
        "clean_data(df)\n",
        "print(\"No. of missing values after cleaning data : \",df.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9xPslpfS_tx",
        "outputId": "9819cab7-13cb-4f62-d9c1-51bb38dc5796"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Manufacturer    Model     Type  ...  Luggage.room  Weight   Origin\n",
            "0        Acura  Integra    Small  ...          11.0    2705  non-USA\n",
            "1        Acura   Legend  Midsize  ...          15.0    3560  non-USA\n",
            "2         Audi       90  Compact  ...          14.0    3375  non-USA\n",
            "3         Audi      100  Midsize  ...          17.0    3405  non-USA\n",
            "4          BMW     535i  Midsize  ...          13.0    3640  non-USA\n",
            "\n",
            "[5 rows x 26 columns]\n",
            "No. of missing values before cleaning data :  13\n",
            "No. of missing values after cleaning data :  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "iii) Write a function to reduce noise (any error in the feature) in individual attributes (2 marks)"
      ],
      "metadata": {
        "id": "sgrWeXR_WWJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pandas.read_csv('/content/drive/MyDrive/Colab Notebooks/Lab 1/Cars93.csv')\n",
        "\n",
        "cols = {}\n",
        "row1 = df.iloc[0]\n",
        "\n",
        "for i in row1.index:\n",
        "    cols[i]=type(row1[i])\n",
        "\n",
        "for i in df.columns:\n",
        "    for j in range(len(df)):\n",
        "        if type(df[i][j])!=cols[i]:\n",
        "            print(df[i][j],i,j)\n",
        "            df.drop(j,inplace==True)\n",
        "    # print(df[i].iloc[0])\n",
        "    # df.drop(df[type(df[i])!=cols[i]].index, inplace = True)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa9LaZ90WW7-",
        "outputId": "43bfaf9c-cbce-40b7-a0de-b74c16671af5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Manufacturer    Model     Type  ...  Luggage.room  Weight   Origin\n",
            "0        Acura  Integra    Small  ...          11.0    2705  non-USA\n",
            "1        Acura   Legend  Midsize  ...          15.0    3560  non-USA\n",
            "2         Audi       90  Compact  ...          14.0    3375  non-USA\n",
            "3         Audi      100  Midsize  ...          17.0    3405  non-USA\n",
            "4          BMW     535i  Midsize  ...          13.0    3640  non-USA\n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "iv) Write a function to encode all the categorical features in the dataset according to the type of\n",
        "variable jointly. (5 Marks)"
      ],
      "metadata": {
        "id": "8cue8CRzWXyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def encode(df):\n",
        "  ndf=df.apply(LabelEncoder().fit_transform)\n",
        "  return ndf\n",
        "\n",
        "new_df = encode(df)\n",
        "print(new_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFNlW7p5Walj",
        "outputId": "ea297ac2-7a49-4880-b99f-e710ff48f473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Manufacturer  Model  Type  ...  Luggage.room  Weight  Origin\n",
            "0             0     48     3  ...             4      24       1\n",
            "1             0     55     2  ...             8      60       1\n",
            "2             1      8     0  ...             7      50       1\n",
            "3             1      0     2  ...            10      52       1\n",
            "4             2      5     2  ...             6      64       1\n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v) Write a function to normalize / scale the features either individually or jointly. (2 Marks)"
      ],
      "metadata": {
        "id": "Hy0CzthoWbKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def scale_data(df):\n",
        "    scaler = preprocessing.MinMaxScaler()\n",
        "    return scaler.fit_transform(df)"
      ],
      "metadata": {
        "id": "Y64A055SWeO2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vi) Write a function to create a random split of the data into train, validation and test sets in the\n",
        "ratio of [70:20:10]. (3 Marks)"
      ],
      "metadata": {
        "id": "NmKJoqpzWexE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_val_test_split(x,y):\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=0.33, random_state=1)\n",
        "\n",
        "    return [x_train, x_val, x_test, y_train, y_val, y_test]"
      ],
      "metadata": {
        "id": "KgkbMmvCWgt8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\\\n",
        "# **Problem 4 (Plotting) :**\n",
        "Plot following functions: (5 Marks) \\\n",
        "\\\n",
        "a) y = 5x + 4 where x ranges from [-10, 10].\n"
      ],
      "metadata": {
        "id": "5cMrC6-0WlU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in range(-10, 11):\n",
        "    x.append(i)\n",
        "    y.append(5*i+4)\n",
        "    \n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-ybiLooSW38b",
        "outputId": "165bb128-650a-4132-c16f-f5b0e49a8422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) y = ln(x) where x > 10 and x < 100."
      ],
      "metadata": {
        "id": "44UzadEWW8-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in range(11, 100):\n",
        "    x.append(i)\n",
        "    y.append(math.log(i))\n",
        "    \n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dPa1jlVkW-VF",
        "outputId": "f71f44ff-0768-4716-b74b-8f62b2b29864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) y = x^2 where x ranges from [-10, 10]."
      ],
      "metadata": {
        "id": "h8TPPk9nW4zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = []\n",
        "y = []\n",
        "\n",
        "for i in range(-10, 11):\n",
        "    x.append(i)\n",
        "    y.append(i*i)\n",
        "    \n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ELl-2fppXIXM",
        "outputId": "75cea11d-d874-48d5-badc-b06becb3d2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\\\n",
        "# **Problem 5 (Evaluation Matrix) :**\n",
        " \\\n",
        "Download colab file and dataset from given link. (10 Marks)\\\n",
        "Some task we already performed on given data in same colab file, Now your task is to perform following operation from inbuilt and scratch :\n",
        "1. Average accuracy and class wise accuracy\n",
        "2. Precision\n",
        "3. Recall\n",
        "4. F1-Score\n",
        "5. Sensitivity\n",
        "6. specificity"
      ],
      "metadata": {
        "id": "DE95Cd0cXZ5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the Necessary Python Libraries and Components"
      ],
      "metadata": {
        "id": "yfz9jnM4xClx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "20q-V4-qwhNN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.linear_model import LogisticRegression as LR\n",
        "from sklearn.tree import DecisionTreeClassifier as DTC\n",
        "from sklearn.metrics import confusion_matrix as cm\n",
        "from sklearn.metrics import precision_score as ps\n",
        "from sklearn.metrics import recall_score as rs\n",
        "from sklearn.metrics import f1_score as f1s\n",
        "from sklearn.metrics import accuracy_score as acc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To Disable Convergence Warnings (For Custom Training)"
      ],
      "metadata": {
        "id": "NBAaHdKV5NcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from warnings import simplefilter\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "simplefilter(\"ignore\", category=ConvergenceWarning)"
      ],
      "metadata": {
        "id": "JoObP-Hr5HQ0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.) Input the Dataset"
      ],
      "metadata": {
        "id": "0k9KnDIDxT40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Reference :- https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Lab 1/data.csv\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "5Pu5cptXxT-4",
        "outputId": "62269a82-da6b-4e8c-8272-a32e6e791383"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1b626ad5-4085-425f-9978-6aea1d687c01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b626ad5-4085-425f-9978-6aea1d687c01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b626ad5-4085-425f-9978-6aea1d687c01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b626ad5-4085-425f-9978-6aea1d687c01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.) Convert the String Labels into easily-interpretable Numerics"
      ],
      "metadata": {
        "id": "MjtAg94u0KQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note :- There are many existing Encoders for converting String to Numeric Labels, but for convenience, we used Pandas.\n",
        "\n",
        "condition_M = data.diagnosis == \"M\"\n",
        "condition_B = data.diagnosis == \"B\"\n",
        "\n",
        "data.loc[condition_M,\"diagnosis\"]=0\n",
        "data.loc[condition_B,\"diagnosis\"]=1\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "vs5EUPrCx6yb",
        "outputId": "41f1f89e-11e9-4cb2-ab14-e83952af4ab3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4fc33457-5f52-4b24-91b0-6bc3247774a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>0</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>0</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>0</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>0</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>0</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>0</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>0</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>0</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>0</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>1</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fc33457-5f52-4b24-91b0-6bc3247774a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4fc33457-5f52-4b24-91b0-6bc3247774a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4fc33457-5f52-4b24-91b0-6bc3247774a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         0  ...                  0.11890          NaN\n",
              "1      842517         0  ...                  0.08902          NaN\n",
              "2    84300903         0  ...                  0.08758          NaN\n",
              "3    84348301         0  ...                  0.17300          NaN\n",
              "4    84358402         0  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         0  ...                  0.07115          NaN\n",
              "565    926682         0  ...                  0.06637          NaN\n",
              "566    926954         0  ...                  0.07820          NaN\n",
              "567    927241         0  ...                  0.12400          NaN\n",
              "568     92751         1  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.) Converting Dataframe into Numpy Arrays (Features and Labels)"
      ],
      "metadata": {
        "id": "SOvmQOBY023p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data.diagnosis.to_numpy().astype('int')                                     # Labels\n",
        "\n",
        "X_data = data.drop(columns=[\"id\",\"diagnosis\",\"Unnamed: 32\"])\n",
        "X = X_data.to_numpy()                                                           # Input Features"
      ],
      "metadata": {
        "id": "kxw_NUvW011A"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.) Splitting the Dataset into Train and Test Portions"
      ],
      "metadata": {
        "id": "6f8ih1Bl0g63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = 0.3\n",
        "user_enable = False\n",
        "\n",
        "x_train,x_test,y_train,y_test = tts(X,Y,test_size=user_prompt,shuffle=user_enable)"
      ],
      "metadata": {
        "id": "ag34WnMA0gln"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.) Model Training and Predicting"
      ],
      "metadata": {
        "id": "UMRmA9jT0TCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note :- Don't worry about the code snippet here, it is just to produce the predictions for the test data portion of each classifier\n",
        "\n",
        "logistic_model = LR()\n",
        "logistic_model.fit(x_train,y_train)\n",
        "logistic_pred = logistic_model.predict(x_test)\n",
        "\n",
        "decision_model = DTC()\n",
        "decision_model.fit(x_train,y_train)\n",
        "decision_pred = decision_model.predict(x_test)"
      ],
      "metadata": {
        "id": "0_rK_IBFzfs4"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.) Evaluation Metrics (Inbulit v/s Scaratch)"
      ],
      "metadata": {
        "id": "8FsxHygi7Zoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "uOLM56wX7zn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inbuilt_matrix_logistic = cm(y_test,logistic_pred)\n",
        "inbuilt_matrix_decision = cm(y_test,decision_pred)\n",
        "\n",
        "print(\"Confusion Matrix for Logistic Regression-based Predictions =>\")\n",
        "print(inbuilt_matrix_logistic)\n",
        "print(\"Confusion Matrix for Decision Tree-based Predictions =>\")\n",
        "print(inbuilt_matrix_decision)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def confusion_matrix(original_set, predicted_set):\n",
        "\n",
        "    conf_mat = [[0,0],[0,0]]\n",
        "    n = len(original_set)\n",
        "\n",
        "    for i in range(n):\n",
        "        if original_set[i]:\n",
        "            if original_set[i] == predicted_set[i]:\n",
        "                conf_mat[1][1] += 1\n",
        "            else:\n",
        "                conf_mat[1][0] += 1\n",
        "        else:\n",
        "            if original_set[i] == predicted_set[i]:\n",
        "                conf_mat[0][0] += 1\n",
        "            else:\n",
        "                conf_mat[0][1] += 1\n",
        "\n",
        "    return np.array(conf_mat)\n",
        "\n",
        "print(\"Confusion Matrix for Logistic Regression-based Predictions from implemented function :\")\n",
        "print(confusion_matrix(y_test,logistic_pred))\n",
        "print(\"Confusion Matrix for Decision Tree-based Predictions from implemented function :\")\n",
        "print(confusion_matrix(y_test,decision_pred))"
      ],
      "metadata": {
        "id": "YP_oItop7lsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44d94f1-6ce7-44aa-a6bb-a2761b7c760c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Logistic Regression-based Predictions =>\n",
            "[[ 38   1]\n",
            " [ 10 122]]\n",
            "Confusion Matrix for Decision Tree-based Predictions =>\n",
            "[[ 36   3]\n",
            " [ 21 111]]\n",
            "Confusion Matrix for Logistic Regression-based Predictions from implemented function :\n",
            "[[ 38   1]\n",
            " [ 10 122]]\n",
            "Confusion Matrix for Decision Tree-based Predictions from implemented function :\n",
            "[[ 36   3]\n",
            " [ 21 111]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average Accuracy"
      ],
      "metadata": {
        "id": "AAFfrbJx7nGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inbuilt_acc_logistic = acc(y_test,logistic_pred)\n",
        "inbuilt_acc_decision = acc(y_test,decision_pred)\n",
        "\n",
        "print(\"Accuracy for Logistic Regression-based Predictions =>\",str(inbuilt_acc_logistic*100)+\"%\")\n",
        "print(\"Accuracy for Decision Tree-based Predictions =>\",str(inbuilt_acc_decision*100)+\"%\")\n",
        "\n",
        "def avg_accuracy(conf_mat,n):\n",
        "\n",
        "    return (conf_mat[0][0]+conf_mat[1][1])/n*100\n",
        "\n",
        "conf_mat_logistic=confusion_matrix(y_test,logistic_pred)\n",
        "conf_mat_decision=confusion_matrix(y_test,decision_pred)\n",
        "n=len(y_test)\n",
        "\n",
        "print()\n",
        "print(f\"Accuracy for Logistic Regression-based Predictions from implemented function : {avg_accuracy(conf_mat_logistic,n)} %\")\n",
        "print(f\"Accuracy for Decision Tree-based Predictions from implemented function : {avg_accuracy(conf_mat_decision,n)} %\")"
      ],
      "metadata": {
        "id": "UAii0HlB7Zux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41602045-e8c9-4fcb-87dc-044b81de1fc2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Logistic Regression-based Predictions => 93.56725146198829%\n",
            "Accuracy for Decision Tree-based Predictions => 85.96491228070175%\n",
            "\n",
            "Accuracy for Logistic Regression-based Predictions from implemented function : 93.56725146198829 %\n",
            "Accuracy for Decision Tree-based Predictions from implemented function : 85.96491228070175 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision"
      ],
      "metadata": {
        "id": "tC-hpfYS7p_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inbuilt_ps_logistic = ps(y_test,logistic_pred)\n",
        "inbuilt_ps_decision = ps(y_test,decision_pred)\n",
        "\n",
        "print(\"Precision for Logistic Regression-based Predictions =>\",str(inbuilt_ps_logistic*100)+\"%\")\n",
        "print(\"Precision for Decision Tree-based Predictions =>\",str(inbuilt_ps_decision*100)+\"%\")\n",
        "\n",
        "def precision(conf_mat):\n",
        "    \n",
        "    return conf_mat[1][1]/(conf_mat[0][1]+conf_mat[1][1])*100\n",
        "\n",
        "print()\n",
        "print(f\"Precision for Logistic Regression-based Predictions from implemented function : {precision(conf_mat_logistic)} %\")\n",
        "print(f\"Precision for Decision Tree-based Predictions from implemented function : {precision(conf_mat_decision)} %\")"
      ],
      "metadata": {
        "id": "DQ2UAn5U7lWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff42fe9-39ec-41a2-c346-2e2242f14f01"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision for Logistic Regression-based Predictions => 99.1869918699187%\n",
            "Precision for Decision Tree-based Predictions => 97.36842105263158%\n",
            "\n",
            "Precision for Logistic Regression-based Predictions from implemented function : 99.1869918699187 %\n",
            "Precision for Decision Tree-based Predictions from implemented function : 97.36842105263158 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recall"
      ],
      "metadata": {
        "id": "VJjpzD1Y7ucm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inbuilt_rs_logistic = rs(y_test,logistic_pred)\n",
        "inbuilt_rs_decision = rs(y_test,decision_pred)\n",
        "\n",
        "print(\"Recall for Logistic Regression-based Predictions =>\",str(inbuilt_rs_logistic*100)+\"%\")\n",
        "print(\"Recall for Decision Tree-based Predictions =>\",str(inbuilt_rs_decision*100)+\"%\")\n",
        "\n",
        "def recall(conf_mat):\n",
        "    \n",
        "    return conf_mat[1][1]/(conf_mat[1][1]+conf_mat[1][0])*100\n",
        "\n",
        "print()\n",
        "print(f\"Recall for Logistic Regression-based Predictions from implemented function : {recall(conf_mat_logistic)} %\")\n",
        "print(f\"Recall for Decision Tree-based Predictions from implemented function : {recall(conf_mat_decision)} %\")"
      ],
      "metadata": {
        "id": "C1WGJmPZ7lda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa6415e-208e-455a-d205-e5db7ce81545"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall for Logistic Regression-based Predictions => 92.42424242424242%\n",
            "Recall for Decision Tree-based Predictions => 84.0909090909091%\n",
            "\n",
            "Recall for Logistic Regression-based Predictions from implemented function : 92.42424242424242 %\n",
            "Recall for Decision Tree-based Predictions from implemented function : 84.0909090909091 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F-1 Score"
      ],
      "metadata": {
        "id": "b_CvAJ3f7wOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inbuilt_f1s_logistic = f1s(y_test,logistic_pred)\n",
        "inbuilt_f1s_decision = f1s(y_test,decision_pred)\n",
        "\n",
        "print(\"F1-Score for Logistic Regression-based Predictions =>\",str(inbuilt_f1s_logistic*100)+\"%\")\n",
        "print(\"F1-Score for Decision Tree-based Predictions =>\",str(inbuilt_f1s_decision*100)+\"%\")\n",
        "\n",
        "def f1_score(conf_mat):\n",
        "    pre = precision(conf_mat)\n",
        "    rec = recall(conf_mat)\n",
        "    return 2*((pre*rec)/(pre+rec))\n",
        "\n",
        "print()\n",
        "print(f\"F1-Score for Logistic Regression-based Predictions from implemented function : {f1_score(conf_mat_logistic)} %\")\n",
        "print(f\"F1-Score for Decision Tree-based Predictions from implemented function : {f1_score(conf_mat_decision)} %\")"
      ],
      "metadata": {
        "id": "gwipguxJ7lk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f419cc-463c-46f9-d17a-1eea2e144615"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1-Score for Logistic Regression-based Predictions => 95.68627450980391%\n",
            "F1-Score for Decision Tree-based Predictions => 90.2439024390244%\n",
            "\n",
            "F1-Score for Logistic Regression-based Predictions from implemented function : 95.68627450980392 %\n",
            "F1-Score for Decision Tree-based Predictions from implemented function : 90.24390243902438 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class-Wise Accuracy"
      ],
      "metadata": {
        "id": "QfGdvDD2HKdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def class_accuracy(conf_mat):\n",
        "    TPR = conf_mat[1][1]/(conf_mat[1][0]+conf_mat[1][1])*100\n",
        "    TNR = conf_mat[0][0]/(conf_mat[0][0]+conf_mat[0][1])*100\n",
        "    return (TPR+TNR)/2\n",
        "\n",
        "print(f\"Class-Wise Accuracy for Logistic Regression-based Predictions : {class_accuracy(conf_mat_logistic)} %\")\n",
        "print(f\"Class-Wise Accuracy for Decision Tree-based Predictions : {class_accuracy(conf_mat_decision)} %\")"
      ],
      "metadata": {
        "id": "NwPQCWGLHK2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f610cdc-7246-45a5-fb4a-984fc3f0f082"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class-Wise Accuracy for Logistic Regression-based Predictions : 94.93006993006992 %\n",
            "Class-Wise Accuracy for Decision Tree-based Predictions : 88.1993006993007 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sensitivity"
      ],
      "metadata": {
        "id": "jZbGtO468-gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sensitivity(conf_mat):\n",
        "    \n",
        "    return conf_mat[1][1]/(conf_mat[1][0]+conf_mat[1][1])*100\n",
        "\n",
        "print(f\"Sensitivity for Logistic Regression-based Predictions : {sensitivity(conf_mat_logistic)} %\")\n",
        "print(f\"Sensitivity for Decision Tree-based Predictions : {sensitivity(conf_mat_decision)} %\")"
      ],
      "metadata": {
        "id": "-514Tgvj8-Uu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381ccba7-205d-48fa-bf36-47d43b5bdb5c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensitivity for Logistic Regression-based Predictions : 92.42424242424242 %\n",
            "Sensitivity for Decision Tree-based Predictions : 84.0909090909091 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specificity"
      ],
      "metadata": {
        "id": "eNJOxp8o8-wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def specificity(conf_mat):\n",
        "    \n",
        "    return conf_mat[0][0]/(conf_mat[0][0]+conf_mat[0][1])*100\n",
        "\n",
        "print(f\"specificity for Logistic Regression-based Predictions : {specificity(conf_mat_logistic)} %\")\n",
        "print(f\"specificity for Decision Tree-based Predictions : {specificity(conf_mat_decision)} %\")"
      ],
      "metadata": {
        "id": "oRmH6Ij07lx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70950316-3217-4836-bc40-c8b314eb2f02"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "specificity for Logistic Regression-based Predictions : 97.43589743589743 %\n",
            "specificity for Decision Tree-based Predictions : 92.3076923076923 %\n"
          ]
        }
      ]
    }
  ]
}